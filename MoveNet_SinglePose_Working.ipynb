{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "10_zkgbZBkIE"
      },
      "source": [
        "# Human Pose Estimation with MoveNet"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9u_VGR6_BmbZ"
      },
      "source": [
        "## Visualization libraries & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtcwSIcgbIVN",
        "outputId": "fafbfabd-91c1-4424-8180-63895b5952ad"
      },
      "outputs": [],
      "source": [
        "!pip install -q imageio\n",
        "!pip install -q opencv-python\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.12.0\n",
        "!pip install tensorflow-hub==0.13.0\n",
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BLeJv-pCCld"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Import matplotlib libraries\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "# Some modules to display an animation using imageio.\n",
        "import imageio\n",
        "from IPython.display import HTML, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEJBMeRb3YUy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Maps bones to h36m\n",
        "KEYPOINT_EDGE_INDS_TO_COLOR_36 = {\n",
        "    (0, 1): 'm',\n",
        "    (1, 2): 'm',\n",
        "    (2, 3): 'm',\n",
        "\n",
        "    (0, 4): 'c',\n",
        "    (4, 5): 'c',\n",
        "    (5, 6): 'c',\n",
        "    \n",
        "    (0, 7): 'y',\n",
        "    (7, 8): 'y',\n",
        "    (8, 9): 'y',\n",
        "    (9, 10): 'y',\n",
        "\n",
        "    (8, 11): 'b',\n",
        "    (11, 12): 'g',\n",
        "    (12, 13): 'b',\n",
        "    \n",
        "    (8, 14): 'r',\n",
        "    (14, 15): 'r',\n",
        "    (15, 16): 'r',\n",
        "\n",
        "}\n",
        "\n",
        "# Maps bones to h36m\n",
        "KEYPOINT_EDGE_INDS_TO_COLOR_36 = {\n",
        "    (0, 1): 'm',\n",
        "    (1, 2): 'm',\n",
        "    (2, 3): 'm',\n",
        "\n",
        "    (0, 4): 'c',\n",
        "    (4, 5): 'c',\n",
        "    (5, 6): 'c',\n",
        "    \n",
        "    (0, 7): 'y',\n",
        "    (7, 8): 'y',\n",
        "    (8, 9): 'y',\n",
        "    (9, 10): 'y',\n",
        "\n",
        "    (8, 11): 'b',\n",
        "    (11, 12): 'g',\n",
        "    (12, 13): 'b',\n",
        "    \n",
        "    (8, 14): 'r',\n",
        "    (14, 15): 'r',\n",
        "    (15, 16): 'r',\n",
        "\n",
        "}\n",
        "\n",
        "# Maps bones\n",
        "KEYPOINT_EDGE_INDS_TO_COLOR = {\n",
        "    (0, 1): 'm',\n",
        "    (0, 2): 'c',\n",
        "    (1, 3): 'm',\n",
        "    (2, 4): 'c',\n",
        "    (0, 5): 'm',\n",
        "    (0, 6): 'c',\n",
        "    (5, 7): 'm',\n",
        "    (7, 9): 'm',\n",
        "    (6, 8): 'c',\n",
        "    (8, 10): 'c',\n",
        "    (5, 6): 'y',\n",
        "    (5, 11): 'm',\n",
        "    (6, 12): 'c',\n",
        "    (11, 12): 'y',\n",
        "    (11, 13): 'm',\n",
        "    (13, 15): 'm',\n",
        "    (12, 14): 'c',\n",
        "    (14, 16): 'c'\n",
        "}\n",
        "\n",
        "def _keypoints_and_edges_for_display(type, keypoints_with_scores, height, width, keypoint_threshold=0.11):\n",
        "\n",
        "  keypoints_all = []\n",
        "  keypoint_edges_all = []\n",
        "  edge_colors = []\n",
        "\n",
        "  if type == \"h36m\":\n",
        "    key_joints = KEYPOINT_EDGE_INDS_TO_COLOR_36\n",
        "  else:\n",
        "    key_joints = KEYPOINT_EDGE_INDS_TO_COLOR\n",
        "\n",
        "  num_instances, _, _, _ = keypoints_with_scores.shape\n",
        "  \n",
        "  for idx in range(num_instances):\n",
        "    kpts_x = keypoints_with_scores[0, idx, :, 1]\n",
        "    kpts_y = keypoints_with_scores[0, idx, :, 0]\n",
        "    kpts_scores = keypoints_with_scores[0, idx, :, 2]\n",
        "    kpts_absolute_xy = np.stack([width * np.array(kpts_x), height * np.array(kpts_y)], axis=-1)\n",
        "    kpts_above_thresh_absolute = kpts_absolute_xy[ kpts_scores > keypoint_threshold, :]\n",
        "    keypoints_all.append(kpts_above_thresh_absolute)\n",
        "\n",
        "    for edge_pair, color in key_joints.items():\n",
        "      if (kpts_scores[edge_pair[0]] > keypoint_threshold and kpts_scores[edge_pair[1]] > keypoint_threshold):\n",
        "        x_start = kpts_absolute_xy[edge_pair[0], 0]\n",
        "        y_start = kpts_absolute_xy[edge_pair[0], 1]\n",
        "        x_end = kpts_absolute_xy[edge_pair[1], 0]\n",
        "        y_end = kpts_absolute_xy[edge_pair[1], 1]\n",
        "        line_seg = np.array([[x_start, y_start], [x_end, y_end]])\n",
        "        keypoint_edges_all.append(line_seg)\n",
        "        edge_colors.append(color)\n",
        "\n",
        "  if keypoints_all:\n",
        "    keypoints_xy = np.concatenate(keypoints_all, axis=0)\n",
        "\n",
        "  # Reshape the array\n",
        "  if keypoint_edges_all:\n",
        "    edges_xy = np.stack(keypoint_edges_all, axis=0)\n",
        "  else:\n",
        "    edges_xy = np.zeros((0, 2, 2))\n",
        "\n",
        "  return keypoints_xy, edges_xy, edge_colors\n",
        "\n",
        "\n",
        "def draw_prediction_on_image(image, keypoints_with_scores, type):\n",
        "\n",
        "  height, width, channel = image.shape\n",
        "  aspect_ratio = float(width) / height\n",
        "  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
        "\n",
        "  # To remove the huge white borders\n",
        "  fig.tight_layout(pad=0)\n",
        "  ax.margins(0)\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_xticklabels([])\n",
        "  plt.axis('off')\n",
        "\n",
        "  im = ax.imshow(image)\n",
        "  line_segments = LineCollection([], linewidths=(4), linestyle='solid')\n",
        "  ax.add_collection(line_segments)\n",
        "  # Turn off tick labels\n",
        "  scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n",
        "\n",
        "  keypoint_locs, keypoint_edges, edge_colors = _keypoints_and_edges_for_display(type, keypoints_with_scores, height, width)\n",
        "\n",
        "  line_segments.set_segments(keypoint_edges)\n",
        "  line_segments.set_color(edge_colors)\n",
        "  if keypoint_edges.shape[0]:\n",
        "    line_segments.set_segments(keypoint_edges)\n",
        "    line_segments.set_color(edge_colors)\n",
        "  if keypoint_locs.shape[0]:\n",
        "    scat.set_offsets(keypoint_locs)\n",
        "\n",
        "  fig.canvas.draw()\n",
        "  image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "  image_from_plot = image_from_plot.reshape(\n",
        "      fig.canvas.get_width_height()[::-1] + (3,))\n",
        "  plt.close(fig)\n",
        "    \n",
        "  return image_from_plot\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UvrN0iQiOxhR"
      },
      "source": [
        "## Load Model from TF hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/float16/4?lite-format=tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeGHgANcT7a1"
      },
      "outputs": [],
      "source": [
        "# Load TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "INPUT_IDX = input_details[0]['index']\n",
        "OUTPUT_IDX = output_details[0]['index']\n",
        "INPUT_DTYPE = input_details[0]['dtype']  # usually float32 for float16 models\n",
        "input_size  = 192\n",
        "\n",
        "\n",
        "def movenet(input_image):\n",
        "    \"\"\"\n",
        "    input_image: tf.Tensor or np.ndarray of shape [1,192,192,3]\n",
        "                 dtype int32 (like SavedModel) or float32\n",
        "    Returns: numpy array [1,1,17,3] with keypoints and scores\n",
        "    \"\"\"\n",
        "    # Match TFLite dtype expectations\n",
        "    if INPUT_DTYPE == np.uint8:\n",
        "        tensor = tf.cast(input_image, tf.uint8).numpy()\n",
        "    else:\n",
        "        # TFLite float models expect [0,1] float32\n",
        "        tensor = tf.cast(input_image, tf.float32).numpy()\n",
        "        if tensor.max() > 1.0:\n",
        "            tensor /= 255.0\n",
        "\n",
        "    interpreter.set_tensor(INPUT_IDX, tensor)\n",
        "    interpreter.invoke()\n",
        "    keypoints_with_scores = interpreter.get_tensor(OUTPUT_IDX)  # [1,1,17,3]\n",
        "    return keypoints_with_scores"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-h1qHYaqD9ap"
      },
      "source": [
        "## Single Image"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ymTVR2I9x22I"
      },
      "source": [
        "This session demonstrates the minumum working example of running the model on a **single image** to predict the 17 human keypoints."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5I3xBq80E3N_"
      },
      "source": [
        "### Load Input Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJZYQ8KYFQ6x"
      },
      "outputs": [],
      "source": [
        "# Load the input image.\n",
        "image_path = 'messi2.jpeg'\n",
        "image = tf.io.read_file(image_path)\n",
        "image = tf.image.decode_jpeg(image)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S_UWRdQxE6WN"
      },
      "source": [
        "### Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "VHmTwACwFW-v",
        "outputId": "700b2a06-164b-4700-8f3d-9fc0a7658744"
      },
      "outputs": [],
      "source": [
        "# Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
        "input_image = tf.expand_dims(image, axis=0)\n",
        "input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
        "\n",
        "# Run model inference.\n",
        "keypoints_with_scores = movenet(input_image)\n",
        "\n",
        "# Visualize the predictions with image.\n",
        "display_image = tf.expand_dims(image, axis=0)\n",
        "display_image = tf.cast(tf.image.resize_with_pad(\n",
        "    display_image, 1280, 1280), dtype=tf.int32)\n",
        "\n",
        "output_overlay = draw_prediction_on_image(np.squeeze(display_image.numpy(), axis=0), keypoints_with_scores, type=\"coco\")\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(output_overlay)\n",
        "_ = plt.axis('off')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qqV8y3e-nrhp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8dO3UkxnJZx",
        "outputId": "a2f268a8-c8d5-46a3-b78e-2840e64008e9"
      },
      "outputs": [],
      "source": [
        "new_keypoints = keypoints_with_scores.copy()\n",
        "new_keypoints.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S47vylMRsoPN",
        "outputId": "18a7a7dc-64c7-4fd0-b59a-61a6538e173a"
      },
      "outputs": [],
      "source": [
        "kp_without_scores = np.array([])\n",
        "\n",
        "for i in range(0, len(new_keypoints[0][0])):\n",
        "   t = np.delete(new_keypoints[0][0][i], -1)\n",
        "   kp_without_scores = np.append(kp_without_scores, t)\n",
        "\n",
        "len(kp_without_scores), kp_without_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sr1QOKWxkE6"
      },
      "outputs": [],
      "source": [
        "def coco_h36m(keypoints):\n",
        "    temporal = keypoints.shape[0]\n",
        "    keypoints_h36m = np.zeros(shape=(keypoints.shape))\n",
        "    htps_keypoints = np.zeros((temporal, 4, 2), dtype=np.float32)\n",
        "\n",
        "    # Reference from \n",
        "    # https://github.com/Vegetebird/StridedTransformer-Pose3D/blob/26161031d0f6cd29df6c56c52f9fd401301e6efd/demo/lib/preprocess.py#L15\n",
        "    # htps_keypoints: head, thorax, pelvis, spine\n",
        "    htps_keypoints[:, 0, 0] = np.mean(keypoints[:, 1:5, 0], axis=1, dtype=np.float32)\n",
        "    htps_keypoints[:, 0, 1] = np.sum(keypoints[:, 1:3, 1], axis=1, dtype=np.float32) - keypoints[:, 0, 1]\n",
        "    htps_keypoints[:, 1, :] = np.mean(keypoints[:, 5:7, :], axis=1, dtype=np.float32)\n",
        "    htps_keypoints[:, 1, :] += (keypoints[:, 0, :] - htps_keypoints[:, 1, :]) / 3\n",
        "\n",
        "    htps_keypoints[:, 2, :] = np.mean(keypoints[:, 11:13, :], axis=1, dtype=np.float32)\n",
        "    htps_keypoints[:, 3, :] = np.mean(keypoints[:, [5, 6, 11, 12], :], axis=1, dtype=np.float32)\n",
        "\n",
        "    keypoints_h36m[:, [10, 8, 0, 7], :] = htps_keypoints\n",
        "    keypoints_h36m[:, [9, 11, 14, 12, 15, 13, 16, 4, 1, 5, 2, 6, 3], :] = keypoints[:, [0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], :]\n",
        "\n",
        "    keypoints_h36m[:, 9, :] -= (keypoints_h36m[:, 9, :] - np.mean(keypoints[:, 5:7, :], axis=1, dtype=np.float32)) / 4\n",
        "    keypoints_h36m[:, 7, 0] += 2*(keypoints_h36m[:, 7, 0] - np.mean(keypoints_h36m[:, [0, 8], 0], axis=1, dtype=np.float32))\n",
        "    keypoints_h36m[:, 8, 1] -= (np.mean(keypoints[:, 1:3, 1], axis=1, dtype=np.float32) - keypoints[:, 0, 1])*2/3\n",
        "\n",
        "    return keypoints_h36m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "8aOinq6LryPU",
        "outputId": "541cc69e-338b-44a6-d7ae-4b89446224ed"
      },
      "outputs": [],
      "source": [
        "# Adjust the shape\n",
        "kp_without_scores = kp_without_scores.reshape(1,17,2)\n",
        "\n",
        "# Convert the COCO to h36m format\n",
        "h36m_without_scores = coco_h36m(kp_without_scores)\n",
        "\n",
        "h36m_without_scores = h36m_without_scores.reshape(17,2)\n",
        "# This helpful for running the keypoints in pose2mesh\n",
        "h36m_without_scores_for_mesh = h36m_without_scores * 1000\n",
        "\n",
        "display(h36m_without_scores)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Swap axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h36m_without_scores_for_mesh_swap = np.zeros(shape=(17, 2))\n",
        "\n",
        "for i in range(0, len(h36m_without_scores_for_mesh_swap)):\n",
        "    h36m_without_scores_for_mesh_swap[i][1], h36m_without_scores_for_mesh_swap[i][0] = \\\n",
        "                                h36m_without_scores_for_mesh[i][0], h36m_without_scores_for_mesh[i][1]\n",
        "\n",
        "h36m_without_scores_for_mesh_swap"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the Keypoints in .npy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_name = image_path.split(\".\")\n",
        "image_name = image_name[0]\n",
        "keypoints_dir = 'keyPoints/{image_name}.npy'.format(image_name=image_name)\n",
        "np.save(keypoints_dir, h36m_without_scores_for_mesh_swap)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = np.load(\"keyPoints/{image_name}.npy\".format(image_name=image_name))\n",
        "a, a.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the Keypoints "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "for i in range(0, len(a)):\n",
        "    plt.plot(a[i][1], a[i][0], 'o')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulipLvFNoyzh"
      },
      "outputs": [],
      "source": [
        "lst = h36m_without_scores.tolist()\n",
        "for i in range (0, len(lst)):\n",
        "  lst[i].append(keypoints_with_scores[0][0][i][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBPw8WTfsht1",
        "outputId": "2f8e1b78-e272-4e36-f1b7-91c425181d2a"
      },
      "outputs": [],
      "source": [
        "h36m_with_scores = np.full((17,3), lst)\n",
        "h36m_with_scores = h36m_with_scores.reshape(1,1,17,3)\n",
        "h36m_with_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "xkBNSsKbwbKi",
        "outputId": "3d12ff83-35d9-4308-aa1e-4ab6f2dd3b5c"
      },
      "outputs": [],
      "source": [
        "output_overlay = draw_prediction_on_image(np.squeeze(display_image.numpy(), axis=0), h36m_with_scores, type=\"h36m\")\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(output_overlay)\n",
        "_ = plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F41QaGRCoaBL"
      },
      "outputs": [],
      "source": [
        "h36m_with_scores.shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KqtQzBCpIJ7Y"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "m",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
